# 系统开发全景：从0到1构建LLM应用

> 目标：回答"系统怎么从需求到上线"、"出问题怎么排查"、"怎么保证稳定运行"

---

## 核心定位：这份文档解决什么问题？

已有文档覆盖：
- **Web2全栈** → 用什么技术框架
- **LLM训练** → 模型怎么工作
- **项目深挖** → 做过什么项目

本文档覆盖：
- **系统开发全景** → **系统怎么从0到1建起来、怎么运维、出问题怎么办**

---

## 目录

- [第一部分：需求分析到架构设计](#第一部分需求分析到架构设计)
- [第二部分：数据工程](#第二部分数据工程)
- [第三部分：模型工程化](#第三部分模型工程化)
- [第四部分：系统可靠性与故障处理](#第四部分系统可靠性与故障处理)
- [第五部分：性能优化](#第五部分性能优化)
- [第六部分：安全与合规](#第六部分安全与合规)
- [第七部分：部署与运维](#第七部分部署与运维)
- [第八部分：20个系统设计面试题](#第八部分20个系统设计面试题)

---

## 第一部分：需求分析到架构设计

### 1.1 需求分析第一性原理

```
用户说"我要一个AI助手"，本质需求是什么？

第一性追问：
1. 解决什么问题？ → 明确业务价值
2. 谁会用？ → 明确用户画像
3. 怎么用？ → 明确使用场景
4. 有多少用？ → 明确规模预期
5. 不能接受什么？ → 明确非功能需求

常见误区：
- 用户说"要ChatGPT一样的" → 实际可能只需要问答，不需要多轮对话
- 技术选型先行 → 应该先搞清楚问题，再选技术
- 追求"最先进" → 合适的才是最好的
```

### 1.2 需求分类与处理

```
功能需求（系统做什么）：
  - 核心功能：RAG问答、文档分析、数据查询
  - 辅助功能：用户管理、权限控制、操作日志

非功能需求（系统要做到什么程度）：
  - 性能：响应时间<2s、并发100 QPS
  - 可用性：99.9% uptime、数据不丢失
  - 安全性：数据加密、权限隔离、审计日志
  - 可扩展性：支持新增数据源、支持模型切换
  - 可维护性：代码规范、文档完整、易于调试

质量属性场景法（以具体场景提问）：
  "周五下午5点，500个用户同时查询，系统要稳定" → 性能+可用性
  "数据被误删后要能恢复" → 数据备份+可追溯
  "新模型上线后出问题要能快速回滚" → 灰度发布+版本管理
```

### 1.3 架构设计决策树

```
第一个决策：单体 vs 微服务 vs 分布式

决策因素：
  团队规模 | 业务复杂度 | 数据规模 | 选型
  ---------|----------|---------|------
  1-3人   | 低       | <10GB   | 单体应用
  3-10人  | 中       | <100GB  | 单体+模块化
  10-50人 | 中高     | <1TB    | 微服务（谨慎）
  >50人   | 高       | >1TB    | 微服务+分布式

第二个决策：同步 vs 异步

  场景               | 选型      | 理由
  -------------------|----------|------
  查询类操作         | 同步HTTP | 简单直接
  耗时任务（文档解析）| 异步队列 | 不阻塞用户
  高并发写入         | 异步队列 | 削峰填谷
  实时性要求极高     | 同步WebSocket | 延迟最低

第三个决策：关系型 vs 非关系型

  数据特征           | 选型        | 理由
  -------------------|-------------|------
  结构化、事务强     | PostgreSQL  | ACID保证
  文档、日志         | MongoDB     | 灵活schema
  向量检索           | Milvus/pgvector | ANN索引
  缓存、会话         | Redis       | 高速读写
  时序数据           | InfluxDB    | 时间序列优化
```

### 1.4 技术选型框架

```
选择技术时问自己四个问题：

1. 团队能力匹配吗？
   - 团队熟悉Python → 选FastAPI/Django，不选Go/Java
   - 有前端经验 → 不换新技术栈
   - 学习成本 < 收益 → 可以考虑新技术

2. 社区成熟度如何？
   - GitHub stars > 10k
   - 最近3个月有更新
   - 能搜到踩坑经验

3. 生产验证过吗？
   - 有大厂案例
   - 有公开的架构文章
   - 不是"玩具项目"

4. 退出成本高吗？
   - 能容易换掉吗？
   - 有标准协议吗？
   - 数据能导出吗？
```

### 1.5 架构图绘制方法

```
分层架构图（面试时手绘）：

┌─────────────────────────────────────────────────────────┐
│                        用户层                             │
│   Web浏览器 │ 移动端API │ 第三方集成 │ 管理后台            │
└────────────────────┬────────────────────────────────────┘
                     │
┌────────────────────▼────────────────────────────────────┐
│                      API网关                              │
│   Nginx/Kong: 认证、限流、日志、路由                     │
└────────────────────┬────────────────────────────────────┘
                     │
         ┌───────────┼───────────┐
         ▼           ▼           ▼
┌────────────┐ ┌──────────┐ ┌────────────┐
│   Web服务   │ │  Worker  │ │  调度服务   │
│  (FastAPI)  │ │  (Celery) │ │  (Airflow) │
│  同步API    │ │  异步任务 │ │  定时任务   │
└──────┬───────┘ └────┬─────┘ └──────┬─────┘
       │              │              │
       ▼              ▼              ▼
┌─────────────────────────────────────────────────────────┐
│                      数据层                               │
│  PostgreSQL │  Redis │  Milvus │  MinIO │  Prometheus   │
└─────────────────────────────────────────────────────────┘

面试技巧：先画核心链路，再补充周边系统
```

---

## 第二部分：数据工程

### 2.1 数据管道设计

```
ETL vs ELT：

ETL（传统数仓）：
  数据源 → 提取 → 转换 → 加载到数仓
  适合：数据量小、转换逻辑复杂

ELT（现代数据湖）：
  数据源 → 提取 → 加载到数仓 → 转换（SQL/Spark）
  适合：数据量大、转换逻辑简单

LLM应用的特点：
  文档 → 解析 → 切分 → Embedding → 向量库
  这是一个"Mini-ELT"，重点在于Embedding质量
```

### 2.2 数据质量评估

```
数据质量五维度：

1. 完整性
   - 检查：缺失值比例、必填字段为空比例
   - 阈值：核心字段缺失率 < 5%
   - 处理：删除、填充、标记

2. 准确性
   - 检查：格式错误、值域越界、逻辑矛盾
   - 示例：日期字段有"2023-13-01"、年龄=200
   - 处理：正则验证、范围检查

3. 一致性
   - 检查：同一实体在不同表中记录不一致
   - 示例：用户A在交易表是"VIP"，在用户表是"普通"
   - 处理：主数据管理、定期对账

4. 及时性
   - 检查：数据延迟、更新频率
   - 指标：T+0（实时）、T+1（日更）、T+7（周更）
   - 处理：增量更新、消息队列

5. 唯一性
   - 检查：重复记录
   - 指标：去重前后的记录数
   - 处理：唯一约束、MD5去重
```

### 2.3 时序数据处理

```
时序数据的特点：
  - 按时间顺序排列
  - 通常有固定采样频率
  - 可能有缺失值、异常值
  - 需要聚合（时、日、月）

处理流程：
  1. 质量检查
     - 范围检查：温度在-50~50℃之间？
     - 变化率检查：相邻两点的差不能过大
     - 平稳性检查：不能有突变（除非有事件记录）

  2. 缺失值处理
     - 短缺失（<3个点）：线性插值
     - 长缺失：标记为null，不插值
     - 周期性缺失：用历史同期均值填充

  3. 异常值处理
     - 3-sigma原则：超出3倍标准差标记为异常
     - 邻域验证：与周围点的均值/中位数比较
     - 人工审核：异常值需人工确认是否为真实事件
```

### 2.4 数据版本管理

```
DVC（Data Version Control）最佳实践：

1. 数据版本化
   dvc add data/raw/
   dvc push  # 上传到远程存储

2. 代码-数据绑定
   git commit  # 记录代码版本
   dvc commit  # 记录数据版本

3. 可追溯性
   dvc checkout v1.0  # 回滚到某个版本的数据
   dvc repro        # 重现某个实验的结果
```

---

## 第三部分：模型工程化

### 3.1 模型开发完整流程

```
实验阶段 → 验证阶段 → 部署阶段 → 监控阶段

┌─────────────────────────────────────────────────────────┐
│  实验阶段（Jupyter Notebook）                              │
│  - 快速迭代、数据探索、模型实验                            │
│  输出：模型权重 + 实验记录                                 │
└────────────────────┬────────────────────────────────────┘
                     │
┌────────────────────▼────────────────────────────────────┐
│  验证阶段（代码模块化）                                   │
│  - 代码重构（.py文件）、单元测试、本地评估                │
│  输出：可训练模块 + 评估报告                               │
└────────────────────┬────────────────────────────────────┘
                     │
┌────────────────────▼────────────────────────────────────┐
│  部署阶段（生产化）                                       │
│  - 模型格式转换、容器化（Docker）、推理服务（vLLM/TGI）   │
│  - 灰度发布（10% → 50% → 100%）                           │
│  输出：推理服务 + 负载均衡                                 │
└────────────────────┬────────────────────────────────────┘
                     │
┌────────────────────▼────────────────────────────────────┐
│  监控阶段（持续运维）                                     │
│  - 延迟监控（P50/P95/P99）、错误率、数据漂移、成本监控    │
│  输出：告警 + 自动回滚/重启                                 │
└─────────────────────────────────────────────────────────┘
```

### 3.2 模型版本管理与A/B测试

```
版本管理策略：

1. 语义化版本：MAJOR.MINOR.PATCH
   - 1.0.0 → 1.1.0：新增功能
   - 1.1.0 → 2.0.0：架构变更

2. 模型注册表（MLflow/Weights & Biases）
   - 记录：模型权重、训练数据、超参数、评估指标

3. A/B测试流程
   - 用户按ID哈希分组（实验组50%，对照组50%）
   - 收集指标：准确率、用户满意度、响应时间
   - 统计检验：t检验、卡方检验

4. 灰度发布（金丝雀部署）
   - 第1天：内部测试用户
   - 第2-3天：5%流量
   - 第4-5天：50%流量
   - 第6天：100%流量
```

### 3.3 模型监控与漂移检测

```
需要监控的指标：

1. 性能指标
   - 延迟：P50 < 500ms, P95 < 2s, P99 < 5s
   - 吞吐量：QPS > 目标值
   - 错误率：< 1%

2. 模型指标
   - 准确率/召回率/F1
   - 用户反馈（点赞/点踩）

3. 数据漂移
   - 输入分布变化（KL散度、JS散度）
   - 检测方法：KS检验、MMD

4. 资源指标
   - GPU利用率：> 80%
   - 显存占用：< 90%

告警规则：
  - 错误率 > 2% → 立即告警
  - P95延迟 > 5s → 告警
  - 数据漂移检测 > 阈值 → 告警
```

### 3.4 模型回滚与应急预案

```
回滚决策树：

检测到问题
    │
    ├─ 错误率飙升（>5%）
    │   └─ 立即回滚到上一版本
    │
    ├─ 延迟升高但无错误
    │   ├─ 检查资源占用
    │   ├─ 如果资源不足 → 扩容
    │   └─ 如果资源充足 → 检查网络/依赖
    │
    ├─ 准确率下降
    │   ├─ 检查数据漂移
    │   └─ 如果无漂移 → 回滚
    │
    └─ GPU OOM
        └─ 减少batch size或扩容

回滚步骤：
  1. 停止流量（负载均衡摘除该实例）
  2. 部署旧版本模型
  3. 健康检查通过后恢复流量
  4. 保存问题现场（日志、数据）用于分析
```

### 3.5 模型成本优化

```
成本优化策略：

1. 模型量化
   - FP32 → FP16：显存减半，速度2倍
   - FP16 → INT8：显存再减半，速度4倍
   - GPTQ/AWQ：离线量化

2. 模型蒸馏
   - 大模型（GPT-4）→ 小模型（Qwen-7B）
   - 用大模型生成训练数据，小模型学习
   - 收益：推理成本降低10倍+

3. 动态路由
   - 简单问题 → 小模型（Qwen-0.5B）
   - 复杂问题 → 大模型（Qwen-7B）
   - 节省成本：30-50%

4. 缓存策略
   - 常见问题缓存（Redis）
   - 向量检索缓存（Milvus）
   - 节省Token：20-40%

5. 批处理
   - 多个请求合并为一个batch
   - 提高GPU利用率
```

---

## 第四部分：系统可靠性与故障处理

### 4.1 高可用架构设计

```
设计原则：
  - 消除单点故障（SPOF）
  - 冗余备份（主备、主主）
  - 故障自动转移（failover）
  - 降级限流（保护系统）

典型架构：

                    ┌─────────┐
                    │  用户   │
                    └────┬────┘
                         │
                ┌────────▼────────┐
                │   负载均衡器     │
                │  (Nginx/HAProxy) │
                └────────┬────────┘
                         │
         ┌───────────────┼───────────────┐
         ▼               ▼               ▼
    ┌─────────┐     ┌─────────┐     ┌─────────┐
    │ 实例1   │     │ 实例2   │     │ 实例3   │
    │(Active) │     │(Standby)│     │(Active) │
    └────┬────┘     └────┬────┘     └────┬────┘
         │               │               │
         └───────────────┼───────────────┘
                         │
              ┌──────────▼──────────┐
              │    共享存储         │
              │  (Redis集群/PG主备) │
              └─────────────────────┘

故障转移流程：
  1. 健康检查失败（心跳超时）
  2. 标记实例为不可用
  3. 负载均衡器将流量转移到健康实例
  4. 通知运维人员
  5. 修复后重新加入集群
```

### 4.2 分布式系统的一致性问题

```
CAP定理：
  - 一致性（Consistency）：所有节点同时看到相同数据
  - 可用性（Availability）：每个请求都能得到响应
  - 分区容错（Partition Tolerance）：系统在网络分区时仍能工作

现实：在分布式系统中，P是必须的，只能在C和A之间权衡

应用场景：
  - 强一致性（CP）：金融交易、库存扣减
    - 方案：分布式事务、两阶段提交（2PC）

  - 最终一致性（AP）：社交动态、点赞数
    - 方案：异步复制、事件溯源

LLM应用的权衡：
  - 用户对话历史：最终一致性（异步写入库）
  - 任务队列：强一致性（确保不丢失）
  - 缓存：弱一致性（接受短暂不一致）
```

### 4.3 故障排查方法论

```
故障排查流程：

1. 定义问题
   - 现象：什么出问题了？
   - 范围：哪些用户/功能受影响？
   - 时间：什么时候开始的？

2. 收集信息
   - 日志：应用日志、系统日志、审计日志
   - 监控：Prometheus/Grafana Dashboard
   - 链路追踪：Jaeger/SkyWalking

3. 定位根因
   - 80/20原则：80%的问题由20%的原因造成
   - 常见根因：
     - 代码Bug（40%）
     - 配置错误（20%）
     - 资源不足（15%）
     - 依赖故障（15%）
     - 数据问题（10%）

4. 临时措施
   - 重启服务
   - 回滚版本
   - 扩容
   - 降级（关闭非核心功能）

5. 永久解决
   - 修复Bug
   - 优化配置
   - 架构调整
   - 监控完善

工具链：
  - 日志：ELK（Elasticsearch + Logstash + Kibana）
  - 监控：Prometheus + Grafana
  - 链路追踪：Jaeger、SkyWalking、Zipkin
```

### 4.4 压力测试与容量规划

```
压力测试类型：

1. 负载测试（Load Testing）
   - 目标：验证系统在预期负载下的表现
   - 方法：逐步增加并发，直到达到目标QPS
   - 工具：Locust、JMeter、k6

2. 压力测试（Stress Testing）
   - 目标：找到系统的极限
   - 方法：持续增加并发，直到系统崩溃

3. 耐久测试（Endurance Testing）
   - 目标：发现内存泄漏、资源耗尽
   - 方法：长时间运行（24小时+）高负载

容量规划公式：
  所需实例数 = (目标QPS × 单请求耗时(秒)) / 实例处理能力

  例：目标100 QPS，单请求耗时0.5s，单实例QPS=50
  → 需要实例数 = (100 × 0.5) / 50 = 1
  → 考虑冗余 ×2 = 2实例
```

---

## 第五部分：性能优化

### 5.1 性能瓶颈识别

```
瓶颈类型与识别方法：

1. CPU瓶颈
   现象：CPU使用率高（>80%）
   工具：top、htop、vmstat
   定位：perf flame graph、py-spy

2. 内存瓶颈
   现象：OOM、频繁GC
   工具：free、vmstat、memory_profiler

3. IO瓶颈（磁盘/网络）
   现象：iowait高、网络延迟大
   工具：iostat、iftop、tcpdump

4. 数据库瓶颈
   现象：慢查询、锁等待
   工具：slow query log、EXPLAIN

Python性能优化：
  1. 算法优化：O(n²) → O(n log n)
  2. 使用内置函数：sum() > for循环
  3. 避免全局解释器锁（GIL）：多进程而非多线程
  4. 使用C扩展：numpy、pandas、numba
```

### 5.2 数据库查询优化

```
查询优化检查清单：

1. 索引使用
   - 确保WHERE、JOIN、ORDER BY字段有索引
   - 复合索引：考虑字段顺序（选择性高的在前）
   - 避免：索引失效（如LIKE '%xxx'）

2. 查询重写
   - 避免：SELECT *
   - 避免：子查询 → 改用JOIN
   - 避免：OR → 改用UNION ALL

3. 分页优化
   - 传统：LIMIT offset, size → offset大时慢
   - 优化：记录上次查询的最大ID（游标分页）

4. 批量操作
   - 批量插入：INSERT INTO ... VALUES (),(),(...)
   - 避免N+1问题：预加载、JOIN
```

### 5.3 缓存策略深度

```
多级缓存架构：

L1: 应用内存缓存（lru_cache、dict）
  - TTL：秒级
  - 容量：MB级

L2: Redis缓存
  - TTL：分钟到小时
  - 容量：GB级

L3: CDN缓存
  - TTL：小时到天
  - 容量：TB级

缓存更新策略：

1. Cache Aside（旁路缓存）— 最常用
   - 读：先读缓存，miss则读DB，再写缓存
   - 写：先写DB，再删除缓存

2. Write Through（写穿）
   - 写：同时写缓存和DB
   - 优点：强一致性

3. Write Back（写回）
   - 写：只写缓存，异步批量写DB
   - 优点：写性能最高

缓存问题与解决：

1. 缓存穿透
   - 问题：查询不存在的数据，每次都查DB
   - 解决：布隆过滤器、缓存空值

2. 缓存击穿
   - 问题：热点key过期，大量请求直接打到DB
   - 解决：互斥锁、热点key永不过期

3. 缓存雪崩
   - 问题：大量key同时过期
   - 解决：过期时间加随机值、多级缓存
```

### 5.4 异步处理与消息队列

```
什么时候需要异步？

场景1：耗时操作
  - 文档解析（PDF → 文本）
  - 数据导出（生成Excel）
  - 模型推理（调用外部LLM API）

场景2：高并发写入
  - 用户行为日志
  - 传感器数据上报

场景3：系统解耦
  - A系统调用B系统，B不稳定
  - 用消息队列隔离

RabbitMQ vs Kafka：

| 维度 | RabbitMQ | Kafka |
|------|----------|-------|
| 延迟 | < 10ms | < 100ms |
| 吞吐量 | 万级 | 百万级 |
| 消息顺序 | 队列内有序 | 分区内有序 |
| 适用 | 任务队列、RPC | 日志收集、流处理 |
```

---

## 第六部分：安全与合规

### 6.1 数据安全

```
数据分类与处理：

1. 敏感数据识别
   - 个人身份信息（PII）：姓名、手机号、身份证
   - 健康数据：病历、体检报告
   - 金融数据：银行卡、交易记录

2. 加密策略
   - 传输加密：HTTPS/TLS 1.3
   - 存储加密：AES-256
   - 密钥管理：密钥轮换、HSM

3. 脱敏与匿名化
   - 屏蔽：手机号 138****1234
   - 哈希：单向hash（用于比对）
   - 令牌化：用随机token替换敏感信息

4. 访问控制
   - 认证（Authentication）：证明你是谁
   - 授权（Authorization）：你能做什么
   - 模型：RBAC（基于角色）、ABAC（基于属性）
```

### 6.2 API安全

```
常见威胁与防御：

1. 注入攻击
   - SQL注入：使用参数化查询、ORM
   - 命令注入：避免直接拼接命令

2. 认证攻击
   - 暴力破解：限流、账户锁定
   - 会话劫持：HTTPS、HttpOnly Cookie

3. 授权绕过
   - 水平越权：严格权限检查
   - 垂直越权：不依赖客户端参数

4. 拒绝服务
   - DDoS：CDN、限流、黑名单
   - 资源耗尽：配额、超时

安全最佳实践：
1. 最小权限原则
2. 默认拒绝（Default Deny）
3. 纵深防御（多层防护）
4. 定期安全审计
```

### 6.3 模型安全

```
LLM应用特有的安全问题：

1. 提示注入（Prompt Injection）
   - 问题：用户输入恶意提示绕过安全限制
   - 防御：
     - 输入过滤：检测恶意关键词
     - 提示工程：在system prompt中强化规则
     - 输出验证：检查返回内容是否违规

2. 对抗攻击
   - 问题：精心构造的输入诱导模型输出错误
   - 防御：
     - 对抗训练：在训练数据中加入对抗样本
     - 输入预处理：清洗、标准化

3. 数据投毒
   - 问题：训练数据被污染
   - 防御：
     - 数据来源审核
     - 数据清洗：异常检测

4. 隐私泄露
   - 问题：模型记忆训练数据中的敏感信息
   - 防御：
     - 训练数据脱敏
     - 差分隐私（Differential Privacy）
```

### 6.4 审计与日志

```
日志分类：

1. 访问日志（Access Log）
   - 内容：时间、用户、操作、资源、结果
   - 用途：审计、行为分析

2. 系统日志（System Log）
   - 内容：应用日志、错误日志、性能日志
   - 级别：DEBUG/INFO/WARN/ERROR/FATAL

3. 审计日志（Audit Log）
   - 内容：敏感操作（登录、删除、导出）
   - 要求：不可篡改、长期保存

日志保留策略：
  - 访问日志：6个月
  - 系统日志：3个月
  - 审计日志：3年
```

---

## 第七部分：部署与运维

### 7.1 容器化部署

```
Dockerfile 最佳实践：

1. 基础镜像选择
   - 生产：python:3.11-slim（小、安全）
   - 开发：python:3.11（完整工具）

2. 多阶段构建
   - 构建阶段：安装依赖、编译
   - 运行阶段：只复制必要的文件

3. 安全加固
   - 非root用户运行
   - 只读文件系统

docker-compose.yml 编排：
  - 服务定义：应用、数据库、缓存
  - 网络隔离：内部网络不对外暴露
  - 卷管理：数据持久化
  - 健康检查：自动重启不健康的容器
```

### 7.2 CI/CD 流水线

```
GitHub Actions 流程：

jobs:
  test:
    - 检出代码
    - 安装依赖
    - 运行测试（pytest）
    - 代码检查（ruff）

  build:
    - 构建Docker镜像
    - 推送到Registry

  deploy:
    - 部署到生产环境
    - 灰度发布
```

### 7.3 监控体系

```
监控四维度：

1. 基础监控
   - CPU、内存、磁盘、网络
   - 工具：Prometheus + Node Exporter

2. 应用监控
   - QPS、延迟、错误率、业务指标
   - 展示：Grafana Dashboard

3. 链路追踪
   - 请求在微服务间的完整路径
   - 工具：Jaeger、SkyWalking

4. 日志监控
   - 错误日志、慢查询日志
   - 工具：ELK、Loki

告警策略：
  - P0（紧急）：立即电话+短信
  - P1（重要）：立即邮件+IM
  - P2（一般）：工单系统
```

### 7.4 故障应急预案

```
常见故障场景：

1. 数据库主库宕机
   - 处理：备用库提升为主库
   - 恢复：原主库作为新备用库

2. Redis宕机
   - 处理：重启或从持久化文件恢复
   - 降级：无缓存运行

3. 模型服务OOM
   - 处理：降低batch size、扩容

4. 磁盘满
   - 处理：清理日志、临时文件、扩容

灾备计划：
  - 数据备份：每日全量 + 实时增量
  - 异地备份：多地容灾
  - 演练：每季度灾备演练
```

---

## 第八部分：20个系统设计面试题

### Q1: 设计一个文档问答系统

```
需求：用户上传PDF，系统回答相关问题，10万文档，1000 QPS

核心组件：
  1. 文档解析：PyPDF2/PyMuPDF → 文本
  2. 文档切分：RecursiveCharacterTextSplitter
  3. 向量化：Embedding模型（BGE-M3）
  4. 向量存储：Milvus/pgvector
  5. 检索：向量检索 + BM25 混合检索
  6. 生成：LLM + Rerank

架构：
  用户 → API网关 → 应用服务 → 向量数据库
              ↓            ↓
           异步队列    LLM服务（vLLM）
              ↓
          文档解析器 → 对象存储

扩展性：
  - 文档增多：分片、水平扩展
  - QPS增高：缓存、CDN、多实例
```

### Q2: 如何保证数据一致性？

```
方案1：乐观锁（读多写少）
  - 版本号机制，更新时检查版本号

方案2：悲观锁（写多读少）
  - SELECT FOR UPDATE

方案3：分布式事务
  - 2PC（两阶段提交）
  - Saga模式（补偿事务）

方案4：最终一致性
  - 异步复制，冲突解决

LLM应用场景：
  - 对话历史：最终一致性
  - 用户画像：最终一致性
  - 任务状态：强一致性
```

### Q3: 如何设计限流策略？

```
限流算法：

1. 固定窗口
   - 实现：Redis计数器
   - 问题：边界突刺

2. 滑动窗口
   - 实现：Redis + 时间戳队列
   - 优点：平滑限流

3. 漏桶
   - 实现：恒定速率处理

4. 令牌桶
   - 实现：Redis + 令牌
   - 适用：允许突发流量

限流维度：
  - 用户级别：每用户100 QPM
  - IP级别：每IP 1000 QPM
  - API级别：不同API不同限制
```

### Q4: 如何设计灰度发布系统？

```
核心组件：

1. 规则引擎
   - 规则类型：白名单、比例、地区、设备

2. 路由层
   - 读取用户特征，匹配灰度规则

3. 配置中心
   - 存储灰度配置，支持动态更新

4. 指标收集
   - QPS、延迟、错误率对比分析

灰度流程：
  v1.0 → 5% → 观察 → 50% → 观察 → 100%
```

### Q5: 如何处理长尾延迟？

```
解决方案：

1. 超时控制
   - 每个层级设置超时
   - API网关：5s，应用服务：3s，数据库：1s

2. 熔断机制
   - 超时立即返回，不等待
   - 返回部分结果（降级）

3. 异步化
   - 同步改异步
   - 返回任务ID，用户轮询结果

4. 快速失败
   - 缓存预热、降级策略
```

### Q6-Q20 简要回答

```
Q6: 实时通知系统
  - 消息队列 + 多渠道发送器 + 重试机制

Q7: 秒杀系统
  - Redis预热库存 + 限流 + 异步订单

Q8: 日志收集系统
  - Filebeat → Kafka → ELK/S3

Q9: 监控告警系统
  - Prometheus + Grafana + AlertManager

Q10: 分布式锁
  - Redis SETNX + 过期时间 + 看门狗

Q11: 定时任务系统
  - Celery Beat / Airflow + 分布式锁

Q12: 配置中心
  - 数据库/Git存储 + 长轮询推送

Q13: API网关
  - Kong / Nginx + 插件机制

Q14: 服务发现
  - Consul / Etcd / Nacos

Q15: 数据库迁移
  - 双写 + 同步工具 + 校验 + 切换

Q16: AB测试平台
  - 分流层 + 实验管理 + 指标收集

Q17: 错误监控系统
  - 日志收集 + 分类聚合 + 告警

Q18: 容量规划
  - 历史监控 + 趋势预测 + 弹性伸缩

Q19: 多地域部署
  - 数据同步 + DNS调度 + 故障切换

Q20: 降级开关
  - 降级等级 + 触发条件 + 降级策略
```

---

## 总结：核心能力地图

```
需求分析：需求拆解、场景化、质量属性
架构设计：单体vs微服务、同步vs异步、一致性权衡
数据工程：ETL/ELT、数据质量、版本管理
模型工程：开发流程、版本管理、AB测试、监控漂移、回滚
性能优化：瓶颈识别、数据库优化、多级缓存、异步队列
安全合规：数据加密、API安全、模型安全、审计日志
部署运维：容器化、CI/CD、监控告警、应急预案
系统设计：20个经典场景设计思路

面试前最后检查：
- [ ] 能画出系统架构图
- [ ] 能说出5种缓存策略
- [ ] 能解释CAP定理在实际中的应用
- [ ] 能设计一个灰度发布方案
- [ ] 能处理常见故障（OOM、数据库宕机、缓存失效）
- [ ] 能做压力测试和容量规划
```

---

**文档完成时间：** 2026-02-28
**目标岗位：** 清华大学 · 大模型应用开发
**配合文档：**
- `Web2_全栈开发完整图景.md`（技术框架对比）
- `LLM_训练与模型完整图景.md`（模型原理与优化）
- `清华岗位_完整冲刺手册_含Challenger拷问.md`（项目深挖）
